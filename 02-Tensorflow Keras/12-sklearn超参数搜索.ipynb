{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = housing.data, housing.target\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split(X, y, random_state=7)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_all, y_train_all, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_scale = StandardScaler()\n",
    "\n",
    "x_train_scale = stand_scale.fit_transform(X_train)\n",
    "x_valid_scale = stand_scale.transform(X_valid)\n",
    "x_test_scale = stand_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (5160,)\n",
      "(5160, 8) (3870,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_scale.shape, y_train.shape)\n",
    "print(x_valid_scale.shape, y_test.shape)\n",
    "print(x_test_scale.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 874us/step - loss: 2.1442 - val_loss: 1.0266\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.8426 - val_loss: 0.8577\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.7609 - val_loss: 0.7992\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 601us/step - loss: 0.7176 - val_loss: 0.7590\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 643us/step - loss: 0.6843 - val_loss: 0.7261\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 600us/step - loss: 0.6547 - val_loss: 0.6972\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.6281 - val_loss: 0.6682\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 600us/step - loss: 0.6052 - val_loss: 0.6438\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 601us/step - loss: 0.5834 - val_loss: 0.6189\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 639us/step - loss: 0.5651 - val_loss: 0.5987\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 621us/step - loss: 0.5486 - val_loss: 0.5806\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 618us/step - loss: 0.5356 - val_loss: 0.5681\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.5236 - val_loss: 0.5549\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 563us/step - loss: 0.5139 - val_loss: 0.5443\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.5057 - val_loss: 0.5356\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 602us/step - loss: 0.4984 - val_loss: 0.5260\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 589us/step - loss: 0.4919 - val_loss: 0.5192\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 606us/step - loss: 0.4863 - val_loss: 0.5132\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 600us/step - loss: 0.4813 - val_loss: 0.5080\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.4767 - val_loss: 0.5027\n"
     ]
    }
   ],
   "source": [
    "# RandomsizedSearchCV\n",
    "# 定义sklean模型的model\n",
    "# 定义参数集合\n",
    "# 搜索参数\n",
    "\n",
    "def build_model(hidden_layer=1, \n",
    "                layer_size=30, \n",
    "                learning_rate=1e-3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(layer_size, activation=\"relu\", input_shape=x_train_scale.shape[1:]))\n",
    "    \n",
    "    for _ in range(hidden_layer -1):\n",
    "        model.add(keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(learning_rate)    \n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2)]\n",
    "sklearn_model = KerasRegressor(build_fn=build_model)\n",
    "\n",
    "history = sklearn_model.fit(x_train_scale, y_train, \n",
    "                    validation_data=(x_valid_scale, y_valid), \n",
    "                    epochs=20, \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plt_learning_curve(history):\n",
    "    pd.DataFrame(history).plot(figsize=(6,4))\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "    \n",
    "plt_learning_curve(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \"hidden_layer\": np.arange(1, 5),\n",
    "    \"layer_size\": np.arange(20, 40),\n",
    "    \"learning_rate\": [1e-4, 3*1e-4, 1e-3, 3*1e-3, 1e-2, 3*1e-2]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search_cv = RandomizedSearchCV(estimator=sklearn_model,\n",
    "                                      param_distributions=param_distributions,\n",
    "                                      n_iter=10,\n",
    "                                      n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.3858 - val_loss: 2.3455\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 820us/step - loss: 1.8668 - val_loss: 1.6750\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 1.4273 - val_loss: 1.3600\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 1.1761 - val_loss: 1.1393\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.9953 - val_loss: 0.9811\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 840us/step - loss: 0.8664 - val_loss: 0.8657\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.7757 - val_loss: 0.7875\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.7136 - val_loss: 0.7327\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.6701 - val_loss: 0.6941\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 0.6391 - val_loss: 0.6648\n",
      "73/73 [==============================] - 0s 520us/step - loss: 0.5889\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.2003 - val_loss: 1.8725\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 823us/step - loss: 1.4980 - val_loss: 1.2773\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 916us/step - loss: 1.0973 - val_loss: 1.0726\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 798us/step - loss: 0.9458 - val_loss: 0.9579\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.8635 - val_loss: 0.8874\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 910us/step - loss: 0.8114 - val_loss: 0.8420\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.7760 - val_loss: 0.8103\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.7501 - val_loss: 0.7865\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.7292 - val_loss: 0.7678\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.7120 - val_loss: 0.7510\n",
      "73/73 [==============================] - 0s 535us/step - loss: 0.6847\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 4.3014 - val_loss: 2.9727\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 939us/step - loss: 1.9982 - val_loss: 1.5755\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 1.2766 - val_loss: 1.2144\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 1.0753 - val_loss: 1.0621\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.9359 - val_loss: 0.9529\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.8451 - val_loss: 0.8740\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.7842 - val_loss: 0.8231\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 916us/step - loss: 0.7438 - val_loss: 0.7889\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 0.7158 - val_loss: 0.7636\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.6952 - val_loss: 0.7451\n",
      "73/73 [==============================] - 0s 533us/step - loss: 0.6965\n",
      "Epoch 1/10\n",
      "  1/291 [..............................] - ETA: 0s - loss: 4.1510WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.7247 - val_loss: 2.4940\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 927us/step - loss: 1.7196 - val_loss: 1.4669\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 852us/step - loss: 1.2176 - val_loss: 1.1752\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 809us/step - loss: 1.0356 - val_loss: 1.0197\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 876us/step - loss: 0.9213 - val_loss: 0.9177\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.8393 - val_loss: 0.8469\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 981us/step - loss: 0.7790 - val_loss: 0.7986\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 838us/step - loss: 0.7355 - val_loss: 0.7640\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 924us/step - loss: 0.7031 - val_loss: 0.7380\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.6779 - val_loss: 0.7176\n",
      "73/73 [==============================] - 0s 560us/step - loss: 0.6635\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 4.1285 - val_loss: 3.2584\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 929us/step - loss: 2.3497 - val_loss: 1.8998\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 851us/step - loss: 1.5532 - val_loss: 1.4151\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 860us/step - loss: 1.2041 - val_loss: 1.1697\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.9975 - val_loss: 1.0063\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 913us/step - loss: 0.8661 - val_loss: 0.8917\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.7747 - val_loss: 0.8084\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.7093 - val_loss: 0.7484\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 969us/step - loss: 0.6636 - val_loss: 0.7078\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.6326 - val_loss: 0.6769\n",
      "73/73 [==============================] - 0s 547us/step - loss: 0.6502\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7653 - val_loss: 1.2627\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 676us/step - loss: 0.7523 - val_loss: 2.1026\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 725us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 646us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 738us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 619us/step - loss: nan - val_loss: nan\n",
      "73/73 [==============================] - 0s 478us/step - loss: nan\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 912us/step - loss: 1.5079 - val_loss: 1.3490\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 639us/step - loss: 0.5714 - val_loss: 0.4597\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 684us/step - loss: 0.4197 - val_loss: 0.4578\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 633us/step - loss: 0.3987 - val_loss: 0.4128\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 749us/step - loss: 0.3863 - val_loss: 0.4669\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 685us/step - loss: 0.3928 - val_loss: 0.3958\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 774us/step - loss: 0.3763 - val_loss: 0.4093\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 764us/step - loss: 0.3723 - val_loss: 0.3841\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 667us/step - loss: 0.3706 - val_loss: 0.3843\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 659us/step - loss: 0.3646 - val_loss: 0.3733\n",
      "73/73 [==============================] - 0s 519us/step - loss: 0.3656\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7614 - val_loss: 12.5167\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 735us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 719us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 658us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 706us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 649us/step - loss: nan - val_loss: nan\n",
      "73/73 [==============================] - 0s 492us/step - loss: nan\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.6074 - val_loss: 0.5175\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 676us/step - loss: 0.4802 - val_loss: 0.5838\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 794us/step - loss: 0.6934 - val_loss: 1.0613\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 637us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 680us/step - loss: nan - val_loss: nan\n",
      "73/73 [==============================] - 0s 451us/step - loss: nan\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 848us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 731us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 594us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 632us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 731us/step - loss: nan - val_loss: nan\n",
      "73/73 [==============================] - 0s 465us/step - loss: nan\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.6420 - val_loss: 2.4926\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 769us/step - loss: 1.8811 - val_loss: 1.6319\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 803us/step - loss: 1.4133 - val_loss: 1.3100\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 1.1672 - val_loss: 1.0996\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.9973 - val_loss: 0.9512\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 807us/step - loss: 0.8769 - val_loss: 0.8540\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 801us/step - loss: 0.7957 - val_loss: 0.7889\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 801us/step - loss: 0.7389 - val_loss: 0.7459\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 806us/step - loss: 0.7009 - val_loss: 0.7181\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 824us/step - loss: 0.6755 - val_loss: 0.6992\n",
      "73/73 [==============================] - 0s 506us/step - loss: 0.6692\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.9033 - val_loss: 2.9429\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 817us/step - loss: 2.1549 - val_loss: 1.7694\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 916us/step - loss: 1.5202 - val_loss: 1.4085\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 797us/step - loss: 1.2860 - val_loss: 1.2382\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 803us/step - loss: 1.1390 - val_loss: 1.1197\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 771us/step - loss: 1.0316 - val_loss: 1.0305\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 803us/step - loss: 0.9525 - val_loss: 0.9617\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.8910 - val_loss: 0.9073\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 809us/step - loss: 0.8431 - val_loss: 0.8645\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 848us/step - loss: 0.8051 - val_loss: 0.8301\n",
      "73/73 [==============================] - 0s 478us/step - loss: 0.7816\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 4.3540 - val_loss: 3.1974\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 807us/step - loss: 2.2201 - val_loss: 1.7476\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 872us/step - loss: 1.3882 - val_loss: 1.2657\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 848us/step - loss: 1.1012 - val_loss: 1.0557\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 775us/step - loss: 0.9280 - val_loss: 0.9092\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 850us/step - loss: 0.8131 - val_loss: 0.8145\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 977us/step - loss: 0.7393 - val_loss: 0.7558\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 838us/step - loss: 0.6933 - val_loss: 0.7217\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 796us/step - loss: 0.6657 - val_loss: 0.7005\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 923us/step - loss: 0.6483 - val_loss: 0.6867\n",
      "73/73 [==============================] - 0s 478us/step - loss: 0.6354\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.8798 - val_loss: 2.7393\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 877us/step - loss: 1.9760 - val_loss: 1.7110\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 802us/step - loss: 1.4043 - val_loss: 1.3624\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 796us/step - loss: 1.1633 - val_loss: 1.1589\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 856us/step - loss: 1.0167 - val_loss: 1.0192\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.9125 - val_loss: 0.9182\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 903us/step - loss: 0.8359 - val_loss: 0.8458\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 754us/step - loss: 0.7768 - val_loss: 0.7914\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 853us/step - loss: 0.7301 - val_loss: 0.7507\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 804us/step - loss: 0.6934 - val_loss: 0.7198\n",
      "73/73 [==============================] - 0s 835us/step - loss: 0.6772\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 4.2073 - val_loss: 3.0357\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 820us/step - loss: 2.0853 - val_loss: 1.6846\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 913us/step - loss: 1.3733 - val_loss: 1.3046\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 798us/step - loss: 1.1479 - val_loss: 1.1271\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 857us/step - loss: 1.0166 - val_loss: 1.0108\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 812us/step - loss: 0.9229 - val_loss: 0.9265\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 920us/step - loss: 0.8528 - val_loss: 0.8667\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 852us/step - loss: 0.8014 - val_loss: 0.8230\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.7648 - val_loss: 0.7923\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 892us/step - loss: 0.7386 - val_loss: 0.7713\n",
      "73/73 [==============================] - 0s 494us/step - loss: 0.7688\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.0773 - val_loss: 0.6306\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 765us/step - loss: 0.6927 - val_loss: 0.5559\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 804us/step - loss: 0.5052 - val_loss: 0.4912\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 804us/step - loss: 0.4571 - val_loss: 0.4499\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 751us/step - loss: 0.4197 - val_loss: 0.4220\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 0.3983 - val_loss: 0.3918\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 824us/step - loss: 0.3848 - val_loss: 0.3835\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3753 - val_loss: 0.3719\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.3759\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.3886\n",
      "73/73 [==============================] - 0s 635us/step - loss: 0.3806\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.8173 - val_loss: 0.5470\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 0.4676\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4581\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.4114\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.4123\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.3893\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.4025\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.3831\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3660\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3660\n",
      "73/73 [==============================] - 0s 731us/step - loss: 0.3520\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8053 - val_loss: 0.5053\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 875us/step - loss: 0.4446 - val_loss: 0.4526\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.4073 - val_loss: 0.4153\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.3897 - val_loss: 0.3956\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 809us/step - loss: 0.3797 - val_loss: 0.3935\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.3692 - val_loss: 0.3807\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.3591 - val_loss: 0.4442\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3557 - val_loss: 0.3924\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 799us/step - loss: 0.3477 - val_loss: 0.3904\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 757us/step - loss: 0.3488 - val_loss: 0.3693\n",
      "73/73 [==============================] - 0s 506us/step - loss: 0.3624\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9924 - val_loss: 0.5804\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 780us/step - loss: 0.4639 - val_loss: 0.4685\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 802us/step - loss: 0.4889 - val_loss: 0.4744\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 801us/step - loss: 0.4807 - val_loss: 0.4325\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.3893 - val_loss: 0.4142\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.3734 - val_loss: 0.3788\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.3623 - val_loss: 0.3855\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.3573 - val_loss: 0.3684\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 865us/step - loss: 0.3496 - val_loss: 0.3992\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 839us/step - loss: 0.3471 - val_loss: 0.3645\n",
      "73/73 [==============================] - 0s 519us/step - loss: 0.3601\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6789 - val_loss: 0.5217\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 838us/step - loss: 0.4493 - val_loss: 0.4669\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4173 - val_loss: 0.4477\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 910us/step - loss: 0.3920 - val_loss: 0.4077\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 866us/step - loss: 0.3733 - val_loss: 0.4034\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 822us/step - loss: 0.3643 - val_loss: 0.3871\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 843us/step - loss: 0.3560 - val_loss: 0.3950\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 816us/step - loss: 0.3483 - val_loss: 0.4526\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.3574 - val_loss: 0.3641\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 841us/step - loss: 0.3376 - val_loss: 0.3546\n",
      " 1/73 [..............................] - ETA: 0s - loss: 0.2136WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "73/73 [==============================] - 0s 587us/step - loss: 0.3601\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.7316 - val_loss: 2.5904\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 777us/step - loss: 1.8792 - val_loss: 1.5202\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 1.2452 - val_loss: 1.1355\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 940us/step - loss: 0.9976 - val_loss: 0.9440\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 821us/step - loss: 0.8603 - val_loss: 0.8300\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 974us/step - loss: 0.7778 - val_loss: 0.7627\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.7267 - val_loss: 0.7221\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 861us/step - loss: 0.6941 - val_loss: 0.6963\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 862us/step - loss: 0.6714 - val_loss: 0.6780\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 934us/step - loss: 0.6541 - val_loss: 0.6638\n",
      "73/73 [==============================] - 0s 560us/step - loss: 0.6199\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.2310 - val_loss: 1.7795\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 814us/step - loss: 1.2554 - val_loss: 1.0626\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 799us/step - loss: 0.9551 - val_loss: 0.9092\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.8402 - val_loss: 0.8217\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.7657 - val_loss: 0.7631\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 866us/step - loss: 0.7162 - val_loss: 0.7260\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.6820 - val_loss: 0.7005\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.6598 - val_loss: 0.6841\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.6438 - val_loss: 0.6716\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.6314 - val_loss: 0.6623\n",
      "73/73 [==============================] - 0s 560us/step - loss: 0.6215\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.6709 - val_loss: 2.4082\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 820us/step - loss: 1.6807 - val_loss: 1.2521\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 862us/step - loss: 1.1168 - val_loss: 0.9891\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.9455 - val_loss: 0.8774\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 862us/step - loss: 0.8346 - val_loss: 0.8086\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 924us/step - loss: 0.7657 - val_loss: 0.7598\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.7210 - val_loss: 0.7298\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 862us/step - loss: 0.6914 - val_loss: 0.7092\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 923us/step - loss: 0.6701 - val_loss: 0.6933\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 852us/step - loss: 0.6535 - val_loss: 0.6803\n",
      "73/73 [==============================] - 0s 551us/step - loss: 0.6511\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 4.1527 - val_loss: 2.9847\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 885us/step - loss: 2.0633 - val_loss: 1.6295\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 873us/step - loss: 1.3396 - val_loss: 1.2822\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 931us/step - loss: 1.1189 - val_loss: 1.1002\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.9755 - val_loss: 0.9683\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 832us/step - loss: 0.8733 - val_loss: 0.8727\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.7978 - val_loss: 0.8044\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 861us/step - loss: 0.7423 - val_loss: 0.7554\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 859us/step - loss: 0.7007 - val_loss: 0.7187\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.6680 - val_loss: 0.6900\n",
      "73/73 [==============================] - 0s 533us/step - loss: 0.6637\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.7415 - val_loss: 2.4038\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 792us/step - loss: 1.7601 - val_loss: 1.4555\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 1.2783 - val_loss: 1.1824\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 1.0757 - val_loss: 1.0318\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 911us/step - loss: 0.9372 - val_loss: 0.9232\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 966us/step - loss: 0.8302 - val_loss: 0.8376\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 851us/step - loss: 0.7550 - val_loss: 0.7779\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 896us/step - loss: 0.7014 - val_loss: 0.7295\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.6633 - val_loss: 0.6999\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 844us/step - loss: 0.6373 - val_loss: 0.6796\n",
      "73/73 [==============================] - 0s 538us/step - loss: 0.6714\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 971us/step - loss: 3.3691 - val_loss: 2.3853\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 693us/step - loss: 1.8531 - val_loss: 1.4579\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 752us/step - loss: 1.2584 - val_loss: 1.0903\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 746us/step - loss: 0.9961 - val_loss: 0.9252\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 796us/step - loss: 0.8706 - val_loss: 0.8529\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 748us/step - loss: 0.8063 - val_loss: 0.8170\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 785us/step - loss: 0.7694 - val_loss: 0.7930\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 755us/step - loss: 0.7447 - val_loss: 0.7771\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 744us/step - loss: 0.7261 - val_loss: 0.7629\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 738us/step - loss: 0.7111 - val_loss: 0.7504\n",
      "73/73 [==============================] - 0s 517us/step - loss: 0.6783\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 956us/step - loss: 4.1668 - val_loss: 3.3558\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 640us/step - loss: 2.7058 - val_loss: 2.3560\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 633us/step - loss: 1.9632 - val_loss: 1.7797\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 687us/step - loss: 1.5028 - val_loss: 1.4039\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 745us/step - loss: 1.2036 - val_loss: 1.1620\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 745us/step - loss: 1.0141 - val_loss: 1.0092\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 744us/step - loss: 0.8962 - val_loss: 0.9142\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 745us/step - loss: 0.8239 - val_loss: 0.8558\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 766us/step - loss: 0.7792 - val_loss: 0.8187\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 764us/step - loss: 0.7503 - val_loss: 0.7940\n",
      "73/73 [==============================] - 0s 530us/step - loss: 0.7354\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 935us/step - loss: 3.1631 - val_loss: 2.5446\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 712us/step - loss: 1.9847 - val_loss: 1.7492\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 741us/step - loss: 1.4477 - val_loss: 1.3558\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 829us/step - loss: 1.1674 - val_loss: 1.1372\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 819us/step - loss: 1.0086 - val_loss: 1.0086\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 734us/step - loss: 0.9134 - val_loss: 0.9302\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 797us/step - loss: 0.8534 - val_loss: 0.8798\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 802us/step - loss: 0.8133 - val_loss: 0.8448\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 756us/step - loss: 0.7846 - val_loss: 0.8191\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 744us/step - loss: 0.7626 - val_loss: 0.7989\n",
      "73/73 [==============================] - 0s 505us/step - loss: 0.7515\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 979us/step - loss: 3.3649 - val_loss: 2.5059\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 747us/step - loss: 1.8205 - val_loss: 1.6064\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 681us/step - loss: 1.2305 - val_loss: 1.2029\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.9599 - val_loss: 0.9891\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 802us/step - loss: 0.8158 - val_loss: 0.8631\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 748us/step - loss: 0.7311 - val_loss: 0.7854\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 748us/step - loss: 0.6789 - val_loss: 0.7370\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 739us/step - loss: 0.6458 - val_loss: 0.7053\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 750us/step - loss: 0.6233 - val_loss: 0.6830\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 744us/step - loss: 0.6070 - val_loss: 0.6665\n",
      "73/73 [==============================] - 0s 500us/step - loss: 0.6893\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 978us/step - loss: 3.3983 - val_loss: 2.1634\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 759us/step - loss: 1.5377 - val_loss: 1.2704\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 802us/step - loss: 1.0157 - val_loss: 0.9597\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 791us/step - loss: 0.8112 - val_loss: 0.8279\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 748us/step - loss: 0.7224 - val_loss: 0.7636\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 809us/step - loss: 0.6795 - val_loss: 0.7299\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 795us/step - loss: 0.6565 - val_loss: 0.7090\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 754us/step - loss: 0.6420 - val_loss: 0.6950\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 737us/step - loss: 0.6314 - val_loss: 0.6840\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 759us/step - loss: 0.6225 - val_loss: 0.6745\n",
      "73/73 [==============================] - 0s 519us/step - loss: 0.6324\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7648 - val_loss: 0.6251\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 810us/step - loss: 0.4837 - val_loss: 0.4473\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 833us/step - loss: 0.4291 - val_loss: 0.4134\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.4172 - val_loss: 0.4102\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3921 - val_loss: 0.3873\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 816us/step - loss: 0.3792 - val_loss: 0.4586\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 920us/step - loss: 0.3733 - val_loss: 0.4340\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 848us/step - loss: 0.3613 - val_loss: 0.5221\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 866us/step - loss: 0.3567 - val_loss: 0.3576\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3509 - val_loss: 0.3544\n",
      "73/73 [==============================] - 0s 546us/step - loss: 0.3496\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.8314 - val_loss: 0.5613\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 803us/step - loss: 0.4871 - val_loss: 0.4833\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 801us/step - loss: 0.4334 - val_loss: 0.4548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 856us/step - loss: 0.4102 - val_loss: 0.5490\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.3951 - val_loss: 0.4182\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 856us/step - loss: 0.3829 - val_loss: 0.4167\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3736 - val_loss: 0.4540\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3636 - val_loss: 0.3757\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.3573 - val_loss: 0.3817\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3494 - val_loss: 0.4158\n",
      "73/73 [==============================] - 0s 522us/step - loss: 0.4133\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.3616 - val_loss: 0.5611\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 820us/step - loss: 0.4641 - val_loss: 0.4614\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 783us/step - loss: 0.4104 - val_loss: 0.4159\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.3840 - val_loss: 0.3895\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3669 - val_loss: 0.3990\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.3603 - val_loss: 0.3669\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 807us/step - loss: 0.3499 - val_loss: 0.3585\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 0.3427 - val_loss: 0.3697\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 802us/step - loss: 0.3399 - val_loss: 0.3540\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.3367 - val_loss: 0.3536\n",
      "73/73 [==============================] - 0s 519us/step - loss: 0.3405\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9001 - val_loss: 0.5622\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 760us/step - loss: 0.4581 - val_loss: 0.4494\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 878us/step - loss: 0.4089 - val_loss: 0.4145\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 871us/step - loss: 0.3840 - val_loss: 0.3907\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 849us/step - loss: 0.3686 - val_loss: 0.4765\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.3711 - val_loss: 0.3920\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.3678 - val_loss: 0.3793\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3529 - val_loss: 0.4004\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3411 - val_loss: 0.3658\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 923us/step - loss: 0.3342 - val_loss: 0.3674\n",
      "73/73 [==============================] - 0s 507us/step - loss: 0.3618\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8038 - val_loss: 0.5521\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 822us/step - loss: 0.4874 - val_loss: 0.4766\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.4423 - val_loss: 0.4418\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 808us/step - loss: 0.4139 - val_loss: 1.0707\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 856us/step - loss: 0.4134 - val_loss: 0.3953\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 809us/step - loss: 0.3842 - val_loss: 0.4206\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3723 - val_loss: 0.3819\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3658 - val_loss: 0.4781\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3618 - val_loss: 0.4030\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3558 - val_loss: 0.3634\n",
      "73/73 [==============================] - 0s 545us/step - loss: 0.3782\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.4374 - val_loss: 0.7512\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 821us/step - loss: 0.6727 - val_loss: 0.6733\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 0.6422 - val_loss: 0.6031\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5699 - val_loss: 0.5687\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5231 - val_loss: 0.5288\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 924us/step - loss: 0.4970 - val_loss: 0.4984\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 852us/step - loss: 0.4747 - val_loss: 0.4838\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 862us/step - loss: 0.4556 - val_loss: 0.4551\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.4385 - val_loss: 0.4383\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.4251 - val_loss: 0.4309\n",
      "73/73 [==============================] - 0s 528us/step - loss: 0.3797\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.5735 - val_loss: 0.7882\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 819us/step - loss: 0.6530 - val_loss: 0.6384\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 0.5736 - val_loss: 0.5931\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 0.5352 - val_loss: 0.5563\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 861us/step - loss: 0.5059 - val_loss: 0.5268\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.4809 - val_loss: 0.5030\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.4596 - val_loss: 0.4822\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 923us/step - loss: 0.4409 - val_loss: 0.4633\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 851us/step - loss: 0.4260 - val_loss: 0.4498\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 809us/step - loss: 0.4127 - val_loss: 0.4368\n",
      "73/73 [==============================] - 0s 574us/step - loss: 0.4103\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.3486 - val_loss: 0.6560\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 923us/step - loss: 0.5692 - val_loss: 0.5867\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 819us/step - loss: 0.5154 - val_loss: 0.5321\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 856us/step - loss: 0.4831 - val_loss: 0.5083\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.4609 - val_loss: 0.4866\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.4438 - val_loss: 0.4691\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 924us/step - loss: 0.4294 - val_loss: 0.4598\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 902us/step - loss: 0.4176 - val_loss: 0.4473\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 866us/step - loss: 0.4093 - val_loss: 0.4429\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.3998 - val_loss: 0.4199\n",
      "73/73 [==============================] - 0s 505us/step - loss: 0.4048\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.3754 - val_loss: 0.8341\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.7275 - val_loss: 0.6894\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6064 - val_loss: 0.6366\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 937us/step - loss: 0.5522 - val_loss: 0.5883\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5104 - val_loss: 0.5438\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 930us/step - loss: 0.4809 - val_loss: 0.5117\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 798us/step - loss: 0.4573 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.4382 - val_loss: 0.4689\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - ETA: 0s - loss: 0.420 - 0s 794us/step - loss: 0.4238 - val_loss: 0.4565\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.4133 - val_loss: 0.4448\n",
      "73/73 [==============================] - 0s 538us/step - loss: 0.4399\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.4504 - val_loss: 0.7182\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 927us/step - loss: 0.6190 - val_loss: 0.6352\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 869us/step - loss: 0.5659 - val_loss: 0.5939\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 807us/step - loss: 0.5301 - val_loss: 0.5521\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 854us/step - loss: 0.5002 - val_loss: 0.5200\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 0.4759 - val_loss: 0.5018\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.4541 - val_loss: 0.4725\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.4395 - val_loss: 0.4547\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.4203 - val_loss: 0.4462\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.4089 - val_loss: 0.4412\n",
      "73/73 [==============================] - 0s 552us/step - loss: 0.4407\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.4526 - val_loss: 1.0955\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 766us/step - loss: 0.8673 - val_loss: 0.7812\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 854us/step - loss: 0.7134 - val_loss: 0.7039\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.6535 - val_loss: 0.6588\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.6114 - val_loss: 0.6207\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 809us/step - loss: 0.5776 - val_loss: 0.5884\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5491 - val_loss: 0.5599\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5251 - val_loss: 0.5365\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5057 - val_loss: 0.5180\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 809us/step - loss: 0.4898 - val_loss: 0.5058\n",
      "73/73 [==============================] - 0s 520us/step - loss: 0.4378\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.0363 - val_loss: 1.0345\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 816us/step - loss: 0.8322 - val_loss: 0.7720\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 833us/step - loss: 0.6859 - val_loss: 0.6958\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 887us/step - loss: 0.6257 - val_loss: 0.6529\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.5901 - val_loss: 0.6172\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 850us/step - loss: 0.5660 - val_loss: 0.5944\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 963us/step - loss: 0.5475 - val_loss: 0.5771\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 913us/step - loss: 0.5334 - val_loss: 0.5615\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 927us/step - loss: 0.5211 - val_loss: 0.5508\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.5099 - val_loss: 0.5447\n",
      "73/73 [==============================] - 0s 546us/step - loss: 0.5135\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.7060 - val_loss: 1.2904\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 770us/step - loss: 0.9836 - val_loss: 0.8315\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.7366 - val_loss: 0.6968\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 906us/step - loss: 0.6444 - val_loss: 0.6536\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 868us/step - loss: 0.6054 - val_loss: 0.6280\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 820us/step - loss: 0.5806 - val_loss: 0.6070\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 916us/step - loss: 0.5604 - val_loss: 0.5888\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 863us/step - loss: 0.5437 - val_loss: 0.5719\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5283 - val_loss: 0.5561\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5149 - val_loss: 0.5415\n",
      " 1/73 [..............................] - ETA: 0s - loss: 0.5483WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "73/73 [==============================] - 0s 560us/step - loss: 0.5124\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.4991 - val_loss: 1.2381\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 819us/step - loss: 0.9234 - val_loss: 0.8264\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 809us/step - loss: 0.7112 - val_loss: 0.6996\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.6269 - val_loss: 0.6487\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5881 - val_loss: 0.6222\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5629 - val_loss: 0.5991\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 923us/step - loss: 0.5445 - val_loss: 0.5808\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 909us/step - loss: 0.5292 - val_loss: 0.5656\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5165 - val_loss: 0.5521\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5056 - val_loss: 0.5404\n",
      "73/73 [==============================] - 0s 560us/step - loss: 0.5249\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.7357 - val_loss: 0.8814\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 983us/step - loss: 0.7704 - val_loss: 0.7752\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 862us/step - loss: 0.7059 - val_loss: 0.7309\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 811us/step - loss: 0.6683 - val_loss: 0.6989\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 0.6368 - val_loss: 0.6692\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.6085 - val_loss: 0.6417\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 816us/step - loss: 0.5819 - val_loss: 0.6154\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 804us/step - loss: 0.5567 - val_loss: 0.5902\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5333 - val_loss: 0.5684\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5116 - val_loss: 0.5460\n",
      "73/73 [==============================] - 0s 535us/step - loss: 0.5358\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.2507 - val_loss: 1.0540\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 820us/step - loss: 0.7992 - val_loss: 0.6688\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 807us/step - loss: 0.6086 - val_loss: 0.6233\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 909us/step - loss: 0.5791 - val_loss: 0.5993\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 862us/step - loss: 0.5595 - val_loss: 0.5788\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 923us/step - loss: 0.5444 - val_loss: 0.5675\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 906us/step - loss: 0.5313 - val_loss: 0.5554\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 862us/step - loss: 0.5205 - val_loss: 0.5418\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 868us/step - loss: 0.5106 - val_loss: 0.5304\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 850us/step - loss: 0.5004 - val_loss: 0.5234\n",
      "73/73 [==============================] - 0s 539us/step - loss: 0.4592\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 2.4513 - val_loss: 1.1785\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 766us/step - loss: 0.8975 - val_loss: 0.8012\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 802us/step - loss: 0.6853 - val_loss: 0.6781\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.6172 - val_loss: 0.6333\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 858us/step - loss: 0.5858 - val_loss: 0.6017\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.5621 - val_loss: 0.5780\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 811us/step - loss: 0.5431 - val_loss: 0.5595\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.5269 - val_loss: 0.5437\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 856us/step - loss: 0.5126 - val_loss: 0.5292\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 899us/step - loss: 0.4996 - val_loss: 0.5166\n",
      "73/73 [==============================] - 0s 546us/step - loss: 0.4933\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.8845 - val_loss: 1.0061\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 840us/step - loss: 0.8068 - val_loss: 0.7849\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.6960 - val_loss: 0.7214\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 862us/step - loss: 0.6503 - val_loss: 0.6813\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.6157 - val_loss: 0.6470\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 924us/step - loss: 0.5874 - val_loss: 0.6174\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.5625 - val_loss: 0.5914\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5410 - val_loss: 0.5670\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5216 - val_loss: 0.5475\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5051 - val_loss: 0.5287\n",
      "73/73 [==============================] - 0s 560us/step - loss: 0.5023\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.3897 - val_loss: 1.3388\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 768us/step - loss: 1.0205 - val_loss: 0.8439\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.7170 - val_loss: 0.7037\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 805us/step - loss: 0.6384 - val_loss: 0.6664\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 861us/step - loss: 0.6095 - val_loss: 0.6491\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.5914 - val_loss: 0.6339\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5759 - val_loss: 0.6192\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 924us/step - loss: 0.5618 - val_loss: 0.6055\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.5491 - val_loss: 0.5905\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.5372 - val_loss: 0.5793\n",
      "73/73 [==============================] - 0s 546us/step - loss: 0.5577\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.0475 - val_loss: 1.1110\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 927us/step - loss: 0.8592 - val_loss: 0.7573\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 813us/step - loss: 0.6578 - val_loss: 0.6668\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 808us/step - loss: 0.5997 - val_loss: 0.6306\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 855us/step - loss: 0.5684 - val_loss: 0.6023\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.551 - 0s 805us/step - loss: 0.5459 - val_loss: 0.5799\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5265 - val_loss: 0.5619\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 859us/step - loss: 0.5109 - val_loss: 0.5451\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 808us/step - loss: 0.4978 - val_loss: 0.5292\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 920us/step - loss: 0.4854 - val_loss: 0.5158\n",
      "73/73 [==============================] - 0s 558us/step - loss: 0.5028\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000019BB3BA3A00>, as the constructor either does not set or modifies parameter layer_size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6a38bf5c21d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m random_search_cv.fit(x_train_scale, y_train, \n\u001b[0m\u001b[0;32m      2\u001b[0m                      \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                      callbacks=callbacks)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# we clone again after setting params in case some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[0;32m    762\u001b[0m                 **self.best_params_))\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000019BB3BA3A00>, as the constructor either does not set or modifies parameter layer_size"
     ]
    }
   ],
   "source": [
    "random_search_cv.fit(x_train_scale, y_train, \n",
    "                     epochs = 10,\n",
    "                     validation_data=(x_valid_scale, y_valid), \n",
    "                     callbacks=callbacks)\n",
    "\n",
    "#cross_validation:训练集分成n份，n-1份训练，最后一份验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'layer_size': 24, 'hidden_layer': 3}\n",
      "-0.36727604269981384\n"
     ]
    }
   ],
   "source": [
    "print(random_search_cv.best_params_)\n",
    "print(random_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = random_search_cv.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.score(x_test_scale, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
