{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: \"machine learning\"\n",
      "value: \"C++\"\n",
      "\n",
      "value: 1.0\n",
      "value: 2.0\n",
      "value: 3.0\n",
      "value: 4.0\n",
      "\n",
      "value: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1.tf.train.Feature(bytes_list, float_list, int64_list)\n",
    "book = [name.encode(\"utf-8\") for name in [\"machine learning\", \"C++\"]]\n",
    "book_list = tf.train.BytesList(value = book)\n",
    "print(book_list)\n",
    "\n",
    "hours = [1.0, 2.0, 3.0, 4.0]\n",
    "hours_floatlist = tf.train.FloatList(value = hours)\n",
    "print(hours_floatlist)\n",
    "\n",
    "count = [9]\n",
    "count_Intlist = tf.train.Int64List(value = count)\n",
    "print(count_Intlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature {\n",
      "  key: \"book_list\"\n",
      "  value {\n",
      "    bytes_list {\n",
      "      value: \"machine learning\"\n",
      "      value: \"C++\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  key: \"count_Intlist\"\n",
      "  value {\n",
      "    int64_list {\n",
      "      value: 9\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  key: \"hours_floatlist\"\n",
      "  value {\n",
      "    float_list {\n",
      "      value: 1.0\n",
      "      value: 2.0\n",
      "      value: 3.0\n",
      "      value: 4.0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.tf.train.Features(feature = {\"key\": XXXX})\n",
    "features = tf.train.Features(feature={\n",
    "    \"book_list\": tf.train.Feature(bytes_list = book_list),\n",
    "    \"hours_floatlist\": tf.train.Feature(float_list = hours_floatlist),\n",
    "    \"count_Intlist\": tf.train.Feature(int64_list = count_Intlist)\n",
    "})\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.tf.train.Example\n",
    "example = tf.train.Example(features = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"\\ni\\n&\\n\\tbook_list\\x12\\x19\\n\\x17\\n\\x10machine learning\\n\\x03C++\\n'\\n\\x0fhours_floatlist\\x12\\x14\\x12\\x12\\n\\x10\\x00\\x00\\x80?\\x00\\x00\\x00@\\x00\\x00@@\\x00\\x00\\x80@\\n\\x16\\n\\rcount_Intlist\\x12\\x05\\x1a\\x03\\n\\x01\\t\"\n"
     ]
    }
   ],
   "source": [
    "# 4.example的序列化\n",
    "serialize_example = example.SerializeToString()\n",
    "print(serialize_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成文件名\n",
    "output_dir = \"tfrecord\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "file_name = \"test.tfrecords\"\n",
    "fullfile_name = os.path.join(output_dir, file_name)\n",
    "\n",
    "# 写入文件 TFRecordWriter\n",
    "with tf.io.TFRecordWriter(path = fullfile_name) as writer:\n",
    "    for _ in range(3):\n",
    "        writer.write(serialize_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"\\ni\\n&\\n\\tbook_list\\x12\\x19\\n\\x17\\n\\x10machine learning\\n\\x03C++\\n'\\n\\x0fhours_floatlist\\x12\\x14\\x12\\x12\\n\\x10\\x00\\x00\\x80?\\x00\\x00\\x00@\\x00\\x00@@\\x00\\x00\\x80@\\n\\x16\\n\\rcount_Intlist\\x12\\x05\\x1a\\x03\\n\\x01\\t\", shape=(), dtype=string)\n",
      "tf.Tensor(b\"\\ni\\n&\\n\\tbook_list\\x12\\x19\\n\\x17\\n\\x10machine learning\\n\\x03C++\\n'\\n\\x0fhours_floatlist\\x12\\x14\\x12\\x12\\n\\x10\\x00\\x00\\x80?\\x00\\x00\\x00@\\x00\\x00@@\\x00\\x00\\x80@\\n\\x16\\n\\rcount_Intlist\\x12\\x05\\x1a\\x03\\n\\x01\\t\", shape=(), dtype=string)\n",
      "tf.Tensor(b\"\\ni\\n&\\n\\tbook_list\\x12\\x19\\n\\x17\\n\\x10machine learning\\n\\x03C++\\n'\\n\\x0fhours_floatlist\\x12\\x14\\x12\\x12\\n\\x10\\x00\\x00\\x80?\\x00\\x00\\x00@\\x00\\x00@@\\x00\\x00\\x80@\\n\\x16\\n\\rcount_Intlist\\x12\\x05\\x1a\\x03\\n\\x01\\t\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 生成dataset TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset(filenames=[fullfile_name])\n",
    "\n",
    "# 读取序列化文件\n",
    "for line in dataset:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning\n",
      "C++\n",
      "machine learning\n",
      "C++\n",
      "machine learning\n",
      "C++\n"
     ]
    }
   ],
   "source": [
    "#读取原来文件内容\n",
    "except_feature = {\n",
    "    \"book_list\": tf.io.VarLenFeature(dtype=tf.string),\n",
    "    \"hours_floatlist\": tf.io.VarLenFeature(dtype=tf.float32),\n",
    "    \"count_Intlist\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "}\n",
    "\n",
    "for serialized_example_tensor in dataset:\n",
    "    example = tf.io.parse_single_example(serialized=serialized_example_tensor, features=except_feature)\n",
    "    books = tf.sparse.to_dense(example[\"book_list\"])\n",
    "    for book in books:\n",
    "        print(book.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写入压缩文件\n",
    "output_dir = \"tfrecord\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "file_name = \"test.tfrecords\" + \".zip\"\n",
    "fullfile_name_zip = os.path.join(output_dir, file_name)\n",
    "\n",
    "# 定义压缩文件类型\n",
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "\n",
    "# 写入压缩文件 TFRecordWriter\n",
    "with tf.io.TFRecordWriter(path = fullfile_name_zip, options=options) as writer:\n",
    "    for _ in range(3):\n",
    "        writer.write(serialize_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning\n",
      "C++\n",
      "machine learning\n",
      "C++\n",
      "machine learning\n",
      "C++\n"
     ]
    }
   ],
   "source": [
    "# 读取压缩文件 compression_type\n",
    "dataset_zip = tf.data.TFRecordDataset(filenames=[fullfile_name_zip],compression_type=\"GZIP\")\n",
    "for serialized_example_tensor in dataset_zip:\n",
    "    example = tf.io.parse_single_example(serialized=serialized_example_tensor, features=except_feature)\n",
    "    books = tf.sparse.to_dense(example[\"book_list\"])\n",
    "    for book in books:\n",
    "        print(book.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
